{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK & tweepy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This tutorial is partly based on [](https://medium.com/analytics-vidhya/twitter-sentiment-analysis-134553698978)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the first step is to remove the noisy data like punctuations, hashtags, @ and others that are not alphanumeric. Only alphanumeric data are meaningful data that can help us in identifying the sentiments. To remove the noisy data, we will import RegexpTokenizer which will split the strings into substrings based on a regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "regexp = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "df['text_token']=df['text'].apply(regexp.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Wir, unterstützen, die, Impfkampagne, Zusamme...\n",
       "1    [Studierende, der, HdM, haben, Ulrich, Land, u...\n",
       "2    [Die, Hochschulen, der, Region, Stuttgart, lad...\n",
       "3    [Seit, Oktober, 2021, ist, Prof, Dr, Bernd, Sc...\n",
       "Name: text_token, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "Now that we have a tokenized version of the alphanumeric data, our next step will be to remove all the common words which aren’t useful for sentiment analysis. Words like about, above, other punctuations, conjunctions, etc are used a lot in any text data but aren’t useful especially for our purpose. These words are called stopwords. We will now remove the stopwords and make our tweets cleaner for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download(‘stopwords’)\n",
    "\n",
    "# make a list of german stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "df['text_token'] = df['text_token'].apply(lambda x: [item for item in x if item not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Wir, unterstützen, Impfkampagne, ZusammenGege...\n",
       "1    [Studierende, HdM, Ulrich, Land, Jörg, Markste...\n",
       "2    [Die, Hochschulen, Region, Stuttgart, laden, M...\n",
       "3    [Seit, Oktober, 2021, Prof, Dr, Bernd, Schmid,...\n",
       "Name: text_token, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase\n",
    "\n",
    "Convert all the tokens into lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove uncommon words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the stopwords, we will remove all the words that have a length <=2. In general, small words (length <=2 ) aren’t useful for sentiment analysis because they have no meaning. These most probably are noise in our analysis. Apart from removing small words, we will convert all the tokens into lowercase. This is because words like ‘apple’ or ‘Apple’ have the same meaning in the sentimental context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- names: A list of common English names compiled by Mark Kantrowitz\n",
    "- stopwords: A list of really common words, like articles, pronouns, prepositions, and conjunctions\n",
    "- state_union: A sample of transcribed State of the Union addresses by different US presidents, compiled by Kathleen Ahrens\n",
    "- twitter_samples: A list of social media phrases posted to Twitter\n",
    "- movie_reviews: Two thousand movie reviews categorized by Bo Pang and Lillian Lee\n",
    "- averaged_perceptron_tagger: A data model that NLTK uses to categorize words into their part of speech\n",
    "- vader_lexicon: A scored list of words and jargon that NLTK references when performing sentiment analysis, created by C.J. Hutto and Eric Gilbert\n",
    "- punkt: A data model created by Jan Strunk that NLTK uses to split full texts into word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /Users/jankirenz/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/names.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jankirenz/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /Users/jankirenz/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/state_union.zip.\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/jankirenz/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/jankirenz/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jankirenz/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/jankirenz/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /Users/jankirenz/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download nltk \n",
    "nltk.download([\n",
    "    \"names\",\n",
    "    \"stopwords\",\n",
    "    \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "    \"movie_reviews\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"vader_lexicon\",\n",
    "    \"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the State of the Union corpus you downloaded earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_t = [w for w in df['text'] if w.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT',\n",
       " 'HARRY',\n",
       " 'S',\n",
       " 'TRUMAN',\n",
       " 'S',\n",
       " 'ADDRESS',\n",
       " 'BEFORE',\n",
       " 'A',\n",
       " 'JOINT',\n",
       " 'SESSION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'CONGRESS',\n",
       " 'April',\n",
       " 'Mr',\n",
       " 'Speaker',\n",
       " 'Mr',\n",
       " 'President',\n",
       " 'Members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Congress',\n",
       " 'It',\n",
       " 'is',\n",
       " 'with',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'I',\n",
       " 'stand',\n",
       " 'before',\n",
       " 'you',\n",
       " 'my',\n",
       " 'friends',\n",
       " 'and',\n",
       " 'colleagues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Congress',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'Only',\n",
       " 'yesterday',\n",
       " 'we',\n",
       " 'laid',\n",
       " 'to',\n",
       " 'rest',\n",
       " 'the',\n",
       " 'mortal',\n",
       " 'remains',\n",
       " 'of',\n",
       " 'our',\n",
       " 'beloved',\n",
       " 'President',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'At',\n",
       " 'a',\n",
       " 'time',\n",
       " 'like',\n",
       " 'this',\n",
       " 'words',\n",
       " 'are',\n",
       " 'inadequate',\n",
       " 'The',\n",
       " 'most',\n",
       " 'eloquent',\n",
       " 'tribute',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'reverent',\n",
       " 'silence',\n",
       " 'Yet',\n",
       " 'in',\n",
       " 'this',\n",
       " 'decisive',\n",
       " 'hour',\n",
       " 'when',\n",
       " 'world',\n",
       " 'events',\n",
       " 'are',\n",
       " 'moving',\n",
       " 'so',\n",
       " 'rapidly',\n",
       " 'our',\n",
       " 'silence',\n",
       " 'might',\n",
       " 'be',\n",
       " 'misunderstood',\n",
       " 'and',\n",
       " 'might',\n",
       " 'give',\n",
       " 'comfort',\n",
       " 'to',\n",
       " 'our',\n",
       " 'enemies',\n",
       " 'In',\n",
       " 'His',\n",
       " 'infinite',\n",
       " 'wisdom',\n",
       " 'Almighty',\n",
       " 'God',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'fit',\n",
       " 'to',\n",
       " 'take',\n",
       " 'from',\n",
       " 'us',\n",
       " 'a',\n",
       " 'great',\n",
       " 'man',\n",
       " 'who',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'was',\n",
       " 'beloved',\n",
       " 'by',\n",
       " 'all',\n",
       " 'humanity',\n",
       " 'No',\n",
       " 'man',\n",
       " 'could',\n",
       " 'possibly',\n",
       " 'fill',\n",
       " 'the',\n",
       " 'tremendous',\n",
       " 'void',\n",
       " 'left',\n",
       " 'by',\n",
       " 'the',\n",
       " 'passing',\n",
       " 'of',\n",
       " 'that',\n",
       " 'noble',\n",
       " 'soul',\n",
       " 'No',\n",
       " 'words',\n",
       " 'can',\n",
       " 'ease',\n",
       " 'the',\n",
       " 'aching',\n",
       " 'hearts',\n",
       " 'of',\n",
       " 'untold',\n",
       " 'millions',\n",
       " 'of',\n",
       " 'every',\n",
       " 'race',\n",
       " 'creed',\n",
       " 'and',\n",
       " 'color',\n",
       " 'The',\n",
       " 'world',\n",
       " 'knows',\n",
       " 'it',\n",
       " 'has',\n",
       " 'lost',\n",
       " 'a',\n",
       " 'heroic',\n",
       " 'champion',\n",
       " 'of',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'Tragic',\n",
       " 'fate',\n",
       " 'has',\n",
       " 'thrust',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'grave',\n",
       " 'responsibilities',\n",
       " 'We',\n",
       " 'must',\n",
       " 'carry',\n",
       " 'on',\n",
       " 'Our',\n",
       " 'departed',\n",
       " 'leader',\n",
       " 'never',\n",
       " 'looked',\n",
       " 'backward',\n",
       " 'He',\n",
       " 'looked',\n",
       " 'forward',\n",
       " 'and',\n",
       " 'moved',\n",
       " 'forward',\n",
       " 'That',\n",
       " 'is',\n",
       " 'what',\n",
       " 'he',\n",
       " 'would',\n",
       " 'want',\n",
       " 'us',\n",
       " 'to',\n",
       " 'do',\n",
       " 'That',\n",
       " 'is',\n",
       " 'what',\n",
       " 'America',\n",
       " 'will',\n",
       " 'do',\n",
       " 'So',\n",
       " 'much',\n",
       " 'blood',\n",
       " 'has',\n",
       " 'already',\n",
       " 'been',\n",
       " 'shed',\n",
       " 'for',\n",
       " 'the',\n",
       " 'ideals',\n",
       " 'which',\n",
       " 'we',\n",
       " 'cherish',\n",
       " 'and',\n",
       " 'for',\n",
       " 'which',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'lived',\n",
       " 'and',\n",
       " 'died',\n",
       " 'that',\n",
       " 'we',\n",
       " 'dare',\n",
       " 'not',\n",
       " 'permit',\n",
       " 'even',\n",
       " 'a',\n",
       " 'momentary',\n",
       " 'pause',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hard',\n",
       " 'fight',\n",
       " 'for',\n",
       " 'victory',\n",
       " 'Today',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'to',\n",
       " 'America',\n",
       " 'for',\n",
       " 'enlightened',\n",
       " 'leadership',\n",
       " 'to',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'progress',\n",
       " 'Such',\n",
       " 'a',\n",
       " 'leadership',\n",
       " 'requires',\n",
       " 'vision',\n",
       " 'courage',\n",
       " 'and',\n",
       " 'tolerance',\n",
       " 'It',\n",
       " 'can',\n",
       " 'be',\n",
       " 'provided',\n",
       " 'only',\n",
       " 'by',\n",
       " 'a',\n",
       " 'united',\n",
       " 'nation',\n",
       " 'deeply',\n",
       " 'devoted',\n",
       " 'to',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'ideals',\n",
       " 'With',\n",
       " 'great',\n",
       " 'humility',\n",
       " 'I',\n",
       " 'call',\n",
       " 'upon',\n",
       " 'all',\n",
       " 'Americans',\n",
       " 'to',\n",
       " 'help',\n",
       " 'me',\n",
       " 'keep',\n",
       " 'our',\n",
       " 'nation',\n",
       " 'united',\n",
       " 'in',\n",
       " 'defense',\n",
       " 'of',\n",
       " 'those',\n",
       " 'ideals',\n",
       " 'which',\n",
       " 'have',\n",
       " 'been',\n",
       " 'so',\n",
       " 'eloquently',\n",
       " 'proclaimed',\n",
       " 'by',\n",
       " 'Franklin',\n",
       " 'Roosevelt',\n",
       " 'I',\n",
       " 'want',\n",
       " 'in',\n",
       " 'turn',\n",
       " 'to',\n",
       " 'assure',\n",
       " 'my',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " 'and',\n",
       " 'all',\n",
       " 'of',\n",
       " 'those',\n",
       " 'who',\n",
       " 'love',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'liberty',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'world',\n",
       " 'that',\n",
       " 'I',\n",
       " 'will',\n",
       " 'support',\n",
       " 'and',\n",
       " 'defend',\n",
       " 'those',\n",
       " 'ideals',\n",
       " 'with',\n",
       " 'all',\n",
       " 'my',\n",
       " 'strength',\n",
       " 'and',\n",
       " 'all',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'That',\n",
       " 'is',\n",
       " 'my',\n",
       " 'duty',\n",
       " 'and',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'not',\n",
       " 'shirk',\n",
       " 'it',\n",
       " 'So',\n",
       " 'that',\n",
       " 'there',\n",
       " 'can',\n",
       " 'be',\n",
       " 'no',\n",
       " 'possible',\n",
       " 'misunderstanding',\n",
       " 'both',\n",
       " 'Germany',\n",
       " 'and',\n",
       " 'Japan',\n",
       " 'can',\n",
       " 'be',\n",
       " 'certain',\n",
       " 'beyond',\n",
       " 'any',\n",
       " 'shadow',\n",
       " 'of',\n",
       " 'a',\n",
       " 'doubt',\n",
       " 'that',\n",
       " 'America',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'the',\n",
       " 'fight',\n",
       " 'for',\n",
       " 'freedom',\n",
       " 'until',\n",
       " 'no',\n",
       " 'vestige',\n",
       " 'of',\n",
       " 'resistance',\n",
       " 'remains',\n",
       " 'We',\n",
       " 'are',\n",
       " 'deeply',\n",
       " 'conscious',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'much',\n",
       " 'hard',\n",
       " 'fighting',\n",
       " 'is',\n",
       " 'still',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'us',\n",
       " 'Having',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'such',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'to',\n",
       " 'make',\n",
       " 'complete',\n",
       " 'victory',\n",
       " 'certain',\n",
       " 'America',\n",
       " 'will',\n",
       " 'never',\n",
       " 'become',\n",
       " 'a',\n",
       " 'party',\n",
       " 'to',\n",
       " 'any',\n",
       " 'plan',\n",
       " 'for',\n",
       " 'partial',\n",
       " 'victory',\n",
       " 'To',\n",
       " 'settle',\n",
       " 'for',\n",
       " 'merely',\n",
       " 'another',\n",
       " 'temporary',\n",
       " 'respite',\n",
       " 'would',\n",
       " 'surely',\n",
       " 'jeopardize',\n",
       " 'the',\n",
       " 'future',\n",
       " 'security',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'world',\n",
       " 'Our',\n",
       " 'demand',\n",
       " 'has',\n",
       " 'been',\n",
       " 'and',\n",
       " 'it',\n",
       " 'remains',\n",
       " 'Unconditional',\n",
       " 'Surrender',\n",
       " 'We',\n",
       " 'will',\n",
       " 'not',\n",
       " 'traffic',\n",
       " 'with',\n",
       " 'the',\n",
       " 'breakers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'on',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'The',\n",
       " 'responsibility',\n",
       " 'for',\n",
       " 'making',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'grave',\n",
       " 'responsibility',\n",
       " 'must',\n",
       " 'rest',\n",
       " 'with',\n",
       " 'the',\n",
       " 'defenders',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'We',\n",
       " 'are',\n",
       " 'not',\n",
       " 'unconscious',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dictates',\n",
       " 'of',\n",
       " 'humanity',\n",
       " 'We',\n",
       " 'do',\n",
       " 'not',\n",
       " 'wish',\n",
       " 'to',\n",
       " 'see',\n",
       " 'unnecessary',\n",
       " 'or',\n",
       " 'unjustified',\n",
       " 'suffering',\n",
       " 'But',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'Go',\n",
       " 'd',\n",
       " 'and',\n",
       " 'of',\n",
       " 'man',\n",
       " 'have',\n",
       " 'been',\n",
       " 'violated',\n",
       " 'and',\n",
       " 'the',\n",
       " 'guilty',\n",
       " 'must',\n",
       " 'not',\n",
       " 'go',\n",
       " 'unpunished',\n",
       " 'Nothing',\n",
       " 'shall',\n",
       " 'shake',\n",
       " 'our',\n",
       " 'determination',\n",
       " 'to',\n",
       " 'punish',\n",
       " 'the',\n",
       " 'war',\n",
       " 'criminals',\n",
       " 'even',\n",
       " 'though',\n",
       " 'we',\n",
       " 'must',\n",
       " 'pursue',\n",
       " 'them',\n",
       " 'to',\n",
       " 'the',\n",
       " 'ends',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'Lasting',\n",
       " 'peace',\n",
       " 'can',\n",
       " 'never',\n",
       " 'be',\n",
       " 'secured',\n",
       " 'if',\n",
       " 'we',\n",
       " 'permit',\n",
       " 'our',\n",
       " 'dangerous',\n",
       " 'opponents',\n",
       " 'to',\n",
       " 'plot',\n",
       " 'future',\n",
       " 'wars',\n",
       " 'with',\n",
       " 'impunity',\n",
       " 'at',\n",
       " 'any',\n",
       " 'mountain',\n",
       " 'retreat',\n",
       " 'however',\n",
       " 'distant',\n",
       " 'In',\n",
       " 'this',\n",
       " 'shrinking',\n",
       " 'world',\n",
       " 'it',\n",
       " 'is',\n",
       " 'futile',\n",
       " 'to',\n",
       " 'seek',\n",
       " 'safety',\n",
       " 'behind',\n",
       " 'geographical',\n",
       " 'barriers',\n",
       " 'Real',\n",
       " 'security',\n",
       " 'will',\n",
       " 'be',\n",
       " 'found',\n",
       " 'only',\n",
       " 'in',\n",
       " 'law',\n",
       " 'and',\n",
       " 'in',\n",
       " 'justice',\n",
       " 'Here',\n",
       " 'in',\n",
       " 'America',\n",
       " 'we',\n",
       " 'have',\n",
       " 'labored',\n",
       " 'long',\n",
       " 'and',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'a',\n",
       " 'social',\n",
       " 'order',\n",
       " 'worthy',\n",
       " 'of',\n",
       " 'our',\n",
       " 'great',\n",
       " 'heritage',\n",
       " 'In',\n",
       " 'our',\n",
       " 'time',\n",
       " 'tremendous',\n",
       " 'progress',\n",
       " 'has',\n",
       " 'been',\n",
       " 'made',\n",
       " 'toward',\n",
       " 'a',\n",
       " 'really',\n",
       " 'democratic',\n",
       " 'way',\n",
       " 'of',\n",
       " 'life',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'assure',\n",
       " 'the',\n",
       " 'forward',\n",
       " 'looking',\n",
       " 'people',\n",
       " 'of',\n",
       " 'America',\n",
       " 'that',\n",
       " 'there',\n",
       " 'w',\n",
       " 'ill',\n",
       " 'be',\n",
       " 'no',\n",
       " 'relaxation',\n",
       " 'in',\n",
       " 'our',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'the',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'the',\n",
       " 'common',\n",
       " 'people',\n",
       " 'In',\n",
       " 'the',\n",
       " 'difficult',\n",
       " 'days',\n",
       " 'ahead',\n",
       " 'unquestionably',\n",
       " 'we',\n",
       " 'shall',\n",
       " 'face',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'staggering',\n",
       " 'proportions',\n",
       " 'However',\n",
       " 'with',\n",
       " 'the',\n",
       " 'faith',\n",
       " 'of',\n",
       " 'our',\n",
       " 'fathers',\n",
       " 'in',\n",
       " 'our',\n",
       " 'hearts',\n",
       " 'we',\n",
       " 'do',\n",
       " 'not',\n",
       " 'fear',\n",
       " 'the',\n",
       " 'future',\n",
       " 'On',\n",
       " 'the',\n",
       " 'battlefields',\n",
       " 'we',\n",
       " 'have',\n",
       " 'frequently',\n",
       " 'faced',\n",
       " 'overwhelming',\n",
       " 'odds',\n",
       " 'and',\n",
       " 'won',\n",
       " 'At',\n",
       " 'home',\n",
       " 'Americans',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'less',\n",
       " 'resolute',\n",
       " 'We',\n",
       " 'shall',\n",
       " 'never',\n",
       " 'cease',\n",
       " 'our',\n",
       " 'struggle',\n",
       " 'to',\n",
       " 'preserve',\n",
       " 'and',\n",
       " 'maintain',\n",
       " 'our',\n",
       " 'American',\n",
       " 'way',\n",
       " 'of',\n",
       " 'life',\n",
       " 'At',\n",
       " 'this',\n",
       " 'moment',\n",
       " 'America',\n",
       " 'along',\n",
       " 'with',\n",
       " 'her',\n",
       " 'brave',\n",
       " 'Allies',\n",
       " 'is',\n",
       " 'paying',\n",
       " 'again',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'for',\n",
       " 'the',\n",
       " 'defense',\n",
       " 'of',\n",
       " 'our',\n",
       " 'freedom',\n",
       " 'With',\n",
       " 'characteristic',\n",
       " 'energy',\n",
       " 'we',\n",
       " 'are',\n",
       " 'assisting',\n",
       " 'in',\n",
       " 'the',\n",
       " 'liberation',\n",
       " 'of',\n",
       " 'entire',\n",
       " 'nations',\n",
       " 'Gradually',\n",
       " 'the',\n",
       " 'shackles',\n",
       " 'of',\n",
       " 'slavery',\n",
       " 'are',\n",
       " 'being',\n",
       " 'broken',\n",
       " 'by',\n",
       " 't',\n",
       " 'he',\n",
       " 'forces',\n",
       " 'of',\n",
       " 'freedom',\n",
       " 'All',\n",
       " 'of',\n",
       " 'us',\n",
       " 'are',\n",
       " 'praying',\n",
       " 'for',\n",
       " 'a',\n",
       " 'speedy',\n",
       " 'victory',\n",
       " 'Every',\n",
       " 'day',\n",
       " 'peace',\n",
       " 'is',\n",
       " 'delayed',\n",
       " 'costs',\n",
       " 'a',\n",
       " 'terrible',\n",
       " 'toll',\n",
       " 'The',\n",
       " 'armies',\n",
       " 'of',\n",
       " 'liberation',\n",
       " 'today',\n",
       " 'are',\n",
       " 'bringing',\n",
       " 'to',\n",
       " 'an',\n",
       " 'end',\n",
       " 'Hitler',\n",
       " 's',\n",
       " 'ghastly',\n",
       " 'threat',\n",
       " 'to',\n",
       " 'dominate',\n",
       " 'the',\n",
       " 'world',\n",
       " 'Tokyo',\n",
       " 'rocks',\n",
       " 'under',\n",
       " 'the',\n",
       " 'weight',\n",
       " 'of',\n",
       " 'our',\n",
       " 'bombs',\n",
       " 'The',\n",
       " 'grand',\n",
       " 'strategy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'Nations',\n",
       " 'war',\n",
       " 'has',\n",
       " 'been',\n",
       " 'determined',\n",
       " 'due',\n",
       " 'in',\n",
       " 'no',\n",
       " 'small',\n",
       " 'measure',\n",
       " 'to',\n",
       " 'the',\n",
       " 'vision',\n",
       " 'of',\n",
       " 'our',\n",
       " 'departed',\n",
       " 'Commander',\n",
       " 'in',\n",
       " 'Chief',\n",
       " 'We',\n",
       " 'are',\n",
       " 'now',\n",
       " 'carrying',\n",
       " 'out',\n",
       " 'our',\n",
       " 'part',\n",
       " 'of',\n",
       " 'that',\n",
       " 'strategy',\n",
       " 'under',\n",
       " 'the',\n",
       " 'able',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'Admiral',\n",
       " 'Leahy',\n",
       " 'General',\n",
       " 'Marshall',\n",
       " 'A',\n",
       " 'dmiral',\n",
       " 'King',\n",
       " 'General',\n",
       " 'Arnold',\n",
       " 'General',\n",
       " 'Eisenhower',\n",
       " 'Admiral',\n",
       " 'Nimitz',\n",
       " 'and',\n",
       " 'General',\n",
       " 'MacArthur',\n",
       " 'I',\n",
       " 'want',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'to',\n",
       " 'know',\n",
       " 'that',\n",
       " 'this',\n",
       " 'direction',\n",
       " 'must',\n",
       " 'and',\n",
       " 'will',\n",
       " 'remain',\n",
       " 'unchanged',\n",
       " 'and',\n",
       " 'unhampered',\n",
       " 'Our',\n",
       " 'debt',\n",
       " 'to',\n",
       " 'the',\n",
       " 'heroic',\n",
       " 'men',\n",
       " 'and',\n",
       " 'valiant',\n",
       " 'women',\n",
       " 'in',\n",
       " 'the',\n",
       " 'service',\n",
       " 'of',\n",
       " 'our',\n",
       " 'country',\n",
       " 'can',\n",
       " 'never',\n",
       " 'be',\n",
       " 'repaid',\n",
       " 'They',\n",
       " 'have',\n",
       " 'earned',\n",
       " 'our',\n",
       " 'undying',\n",
       " 'gratitude',\n",
       " 'America',\n",
       " 'will',\n",
       " 'never',\n",
       " 'forget',\n",
       " 'their',\n",
       " 'sacrifices',\n",
       " 'Because',\n",
       " 'of',\n",
       " 'these',\n",
       " 'sacrifices',\n",
       " 'the',\n",
       " 'dawn',\n",
       " 'of',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'throughout',\n",
       " 'th',\n",
       " 'e',\n",
       " 'world',\n",
       " 'slowly',\n",
       " 'casts',\n",
       " 'its',\n",
       " 'gleam',\n",
       " 'across',\n",
       " 'the',\n",
       " 'horizon',\n",
       " 'Our',\n",
       " 'forefathers',\n",
       " 'came',\n",
       " 'to',\n",
       " 'our',\n",
       " 'rugged',\n",
       " 'shores',\n",
       " 'in',\n",
       " 'search',\n",
       " 'of',\n",
       " 'religious',\n",
       " 'tolerance',\n",
       " 'political',\n",
       " 'freedom',\n",
       " 'and',\n",
       " 'economic',\n",
       " 'opportunity',\n",
       " 'For',\n",
       " 'those',\n",
       " 'fundamental',\n",
       " 'rights',\n",
       " 'they',\n",
       " 'risked',\n",
       " 'their',\n",
       " 'lives',\n",
       " 'We',\n",
       " 'well',\n",
       " 'know',\n",
       " 'today',\n",
       " 'that',\n",
       " 'such',\n",
       " 'rights',\n",
       " 'can',\n",
       " 'be',\n",
       " 'preserved',\n",
       " 'only',\n",
       " 'by',\n",
       " 'constant',\n",
       " 'vigilance',\n",
       " 'the',\n",
       " 'eternal',\n",
       " 'price',\n",
       " 'of',\n",
       " 'liberty',\n",
       " 'Within',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'after',\n",
       " 'I',\n",
       " 'took',\n",
       " 'the',\n",
       " 'oath',\n",
       " 'of',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you build a list of individual words with the corpus’s .words() method, but you use str.isalpha() to include only the words that are made up of letters. Otherwise, your word list may end up with “words” that are only punctuation marks."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "463226f144cc21b006ce6927bfc93dd00694e52c8bc6857abb6e555b983749e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
